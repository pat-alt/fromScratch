<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 VC theory | From Scratch</title>
  <meta name="description" content="A collection of ideas, notes, exercises and code." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 VC theory | From Scratch" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A collection of ideas, notes, exercises and code." />
  <meta name="github-repo" content="https://github.com/pat-alt/fromScratch.git" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 VC theory | From Scratch" />
  
  <meta name="twitter:description" content="A collection of ideas, notes, exercises and code." />
  

<meta name="author" content="Patrick Altmeyer" />


<meta name="date" content="2021-03-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="www/icon.ico" type="image/x-icon" />
<link rel="prev" href="emp.html"/>
<link rel="next" href="class.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.2/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.2.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.52.2/plotly-latest.min.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.16/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/nouislider-7.0.10/jquery.nouislider.min.css" rel="stylesheet" />
<script src="libs/nouislider-7.0.10/jquery.nouislider.min.js"></script>
<link href="libs/selectize-0.12.0/selectize.bootstrap3.css" rel="stylesheet" />
<script src="libs/selectize-0.12.0/selectize.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#resources"><i class="fa fa-check"></i>Resources</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#r-package"><i class="fa fa-check"></i>R package</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#python-code"><i class="fa fa-check"></i>Python code</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#session-info"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-author.html"><a href="about-the-author.html"><i class="fa fa-check"></i>About the Author</a></li>
<li class="part"><span><b>I Part I</b></span></li>
<li class="chapter" data-level="1" data-path="introductory-topics.html"><a href="introductory-topics.html"><i class="fa fa-check"></i><b>1</b> Introductory topics</a></li>
<li class="chapter" data-level="2" data-path="conc.html"><a href="conc.html"><i class="fa fa-check"></i><b>2</b> Concentration inequalities</a>
<ul>
<li class="chapter" data-level="2.1" data-path="conc.html"><a href="conc.html#conc-mean"><i class="fa fa-check"></i><b>2.1</b> Empirical mean</a></li>
<li class="chapter" data-level="2.2" data-path="conc.html"><a href="conc.html#simple-non-asymptotic-concentration-inequalities"><i class="fa fa-check"></i><b>2.2</b> Simple non-asymptotic concentration inequalities</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="conc.html"><a href="conc.html#conc-markov"><i class="fa fa-check"></i><b>2.2.1</b> Markov’s inequality</a></li>
<li class="chapter" data-level="2.2.2" data-path="conc.html"><a href="conc.html#chebychevs-inequality"><i class="fa fa-check"></i><b>2.2.2</b> Chebychev’s inequality</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="conc.html"><a href="conc.html#asympotic-concentration-inequalities"><i class="fa fa-check"></i><b>2.3</b> Asympotic concentration inequalities</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="conc.html"><a href="conc.html#central-limit-theorem"><i class="fa fa-check"></i><b>2.3.1</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="conc.html"><a href="conc.html#exponential-non-asymptotic-concentration-inequalities"><i class="fa fa-check"></i><b>2.4</b> Exponential non-asymptotic concentration inequalities</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="conc.html"><a href="conc.html#chernoff-bounds"><i class="fa fa-check"></i><b>2.4.1</b> Chernoff bounds</a></li>
<li class="chapter" data-level="2.4.2" data-path="conc.html"><a href="conc.html#conc-hoeff"><i class="fa fa-check"></i><b>2.4.2</b> Hoeffding’s Inequality</a></li>
<li class="chapter" data-level="2.4.3" data-path="conc.html"><a href="conc.html#bernsteins-inequality"><i class="fa fa-check"></i><b>2.4.3</b> Bernstein’s inequality</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="conc.html"><a href="conc.html#conc-examples"><i class="fa fa-check"></i><b>2.5</b> Examples</a></li>
<li class="chapter" data-level="2.6" data-path="conc.html"><a href="conc.html#appendix"><i class="fa fa-check"></i><b>2.6</b> Appendix</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="conc.html"><a href="conc.html#example-of-a-moment-generating-function"><i class="fa fa-check"></i><b>2.6.1</b> Example of a moment generating function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="det-opt.html"><a href="det-opt.html"><i class="fa fa-check"></i><b>3</b> Optimization</a>
<ul>
<li class="chapter" data-level="3.1" data-path="det-opt.html"><a href="det-opt.html#line-search"><i class="fa fa-check"></i><b>3.1</b> Line search</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="det-opt.html"><a href="det-opt.html#methodology"><i class="fa fa-check"></i><b>3.1.1</b> Methodology</a></li>
<li class="chapter" data-level="3.1.2" data-path="det-opt.html"><a href="det-opt.html#results"><i class="fa fa-check"></i><b>3.1.2</b> Results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="emp.html"><a href="emp.html"><i class="fa fa-check"></i><b>4</b> Empirical risk minimization</a>
<ul>
<li class="chapter" data-level="4.1" data-path="emp.html"><a href="emp.html#emp-risks"><i class="fa fa-check"></i><b>4.1</b> Excess risk and overfitting error</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="emp.html"><a href="emp.html#data-splitting"><i class="fa fa-check"></i><b>4.1.1</b> Data splitting</a></li>
<li class="chapter" data-level="4.1.2" data-path="emp.html"><a href="emp.html#leave-one-out-cross-validation"><i class="fa fa-check"></i><b>4.1.2</b> Leave-one-out cross-validation</a></li>
<li class="chapter" data-level="4.1.3" data-path="emp.html"><a href="emp.html#realizable-case"><i class="fa fa-check"></i><b>4.1.3</b> Realizable case</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="emp.html"><a href="emp.html#rademacher-averages"><i class="fa fa-check"></i><b>4.2</b> Rademacher averages</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="emp.html"><a href="emp.html#finite-class-of-classifiers"><i class="fa fa-check"></i><b>4.2.1</b> Finite class of classifiers</a></li>
<li class="chapter" data-level="4.2.2" data-path="emp.html"><a href="emp.html#infinitely-many-classifiers"><i class="fa fa-check"></i><b>4.2.2</b> Infinitely many classifiers</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="emp.html"><a href="emp.html#towards-vc-theory"><i class="fa fa-check"></i><b>4.3</b> Towards VC theory</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="vc.html"><a href="vc.html"><i class="fa fa-check"></i><b>5</b> VC theory</a>
<ul>
<li class="chapter" data-level="5.1" data-path="vc.html"><a href="vc.html#vc-dimension"><i class="fa fa-check"></i><b>5.1</b> VC dimension</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="vc.html"><a href="vc.html#feature-maps"><i class="fa fa-check"></i><b>5.1.1</b> Feature maps</a></li>
<li class="chapter" data-level="5.1.2" data-path="vc.html"><a href="vc.html#examples"><i class="fa fa-check"></i><b>5.1.2</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="vc.html"><a href="vc.html#stuctural-risk-minimization"><i class="fa fa-check"></i><b>5.2</b> Stuctural risk minimization</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="class.html"><a href="class.html"><i class="fa fa-check"></i><b>6</b> Classification</a>
<ul>
<li class="chapter" data-level="6.1" data-path="class.html"><a href="class.html#binary-classification"><i class="fa fa-check"></i><b>6.1</b> Binary classification</a></li>
<li class="chapter" data-level="6.2" data-path="class.html"><a href="class.html#class-knn"><i class="fa fa-check"></i><b>6.2</b> Nearest Neighbour</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="class.html"><a href="class.html#nn"><i class="fa fa-check"></i><b>6.2.1</b> 1NN</a></li>
<li class="chapter" data-level="6.2.2" data-path="class.html"><a href="class.html#knn"><i class="fa fa-check"></i><b>6.2.2</b> KNN</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="class.html"><a href="class.html#linear-classification"><i class="fa fa-check"></i><b>6.3</b> Linear Classification</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="class.html"><a href="class.html#perceptron"><i class="fa fa-check"></i><b>6.3.1</b> Perceptron</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regr.html"><a href="regr.html"><i class="fa fa-check"></i><b>7</b> Regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="regr.html"><a href="regr.html#regr-ols"><i class="fa fa-check"></i><b>7.1</b> Ordinary least-squares</a></li>
<li class="chapter" data-level="7.2" data-path="regr.html"><a href="regr.html#regr-wls"><i class="fa fa-check"></i><b>7.2</b> Weighted least-squares</a></li>
<li class="chapter" data-level="7.3" data-path="regr.html"><a href="regr.html#class-logit"><i class="fa fa-check"></i><b>7.3</b> Logisitic regression</a></li>
<li class="chapter" data-level="7.4" data-path="conc.html"><a href="conc.html#appendix"><i class="fa fa-check"></i><b>7.4</b> Appendix</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="regr.html"><a href="regr.html#app-wls"><i class="fa fa-check"></i><b>7.4.1</b> Weighted least-squares</a></li>
<li class="chapter" data-level="7.4.2" data-path="regr.html"><a href="regr.html#irls"><i class="fa fa-check"></i><b>7.4.2</b> Iterative reweighted least-squares</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="complex.html"><a href="complex.html"><i class="fa fa-check"></i><b>8</b> Complexity regularization</a>
<ul>
<li class="chapter" data-level="8.1" data-path="complex.html"><a href="complex.html#reg-bias"><i class="fa fa-check"></i><b>8.1</b> Bias-variance tradeoff</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="dim-red.html"><a href="dim-red.html"><i class="fa fa-check"></i><b>9</b> Dimensionality reduction</a>
<ul>
<li class="chapter" data-level="9.1" data-path="dim-red.html"><a href="dim-red.html#random-projections"><i class="fa fa-check"></i><b>9.1</b> Random projections</a></li>
<li class="chapter" data-level="9.2" data-path="dim-red.html"><a href="dim-red.html#pca"><i class="fa fa-check"></i><b>9.2</b> PCA</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="dim-red.html"><a href="dim-red.html#the-maths-behind-pca"><i class="fa fa-check"></i><b>9.2.1</b> The maths behind PCA</a></li>
<li class="chapter" data-level="9.2.2" data-path="dim-red.html"><a href="dim-red.html#an-intuitive-example"><i class="fa fa-check"></i><b>9.2.2</b> An intuitive example</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="dim-red.html"><a href="dim-red.html#pca-for-feature-extraction"><i class="fa fa-check"></i><b>9.3</b> PCA for feature extraction</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="dim-red.html"><a href="dim-red.html#squared-elements-of-eigenvectors"><i class="fa fa-check"></i><b>9.3.1</b> Squared elements of eigenvectors</a></li>
<li class="chapter" data-level="9.3.2" data-path="dim-red.html"><a href="dim-red.html#svd"><i class="fa fa-check"></i><b>9.3.2</b> SVD</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="dim-red.html"><a href="dim-red.html#high-dimensional-data"><i class="fa fa-check"></i><b>9.4</b> High-dimensional data</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="dim-red.html"><a href="dim-red.html#regularized-svd"><i class="fa fa-check"></i><b>9.4.1</b> Regularized SVD</a></li>
<li class="chapter" data-level="9.4.2" data-path="dim-red.html"><a href="dim-red.html#fast-partial-svd"><i class="fa fa-check"></i><b>9.4.2</b> Fast, partial SVD</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="dim-red.html"><a href="dim-red.html#forward-search"><i class="fa fa-check"></i><b>9.5</b> Forward search</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="subsample.html"><a href="subsample.html"><i class="fa fa-check"></i><b>10</b> Subsampling</a>
<ul>
<li class="chapter" data-level="10.1" data-path="subsample.html"><a href="subsample.html#subsample-motivation"><i class="fa fa-check"></i><b>10.1</b> Motivation</a></li>
<li class="chapter" data-level="10.2" data-path="subsample.html"><a href="subsample.html#subsample-methods"><i class="fa fa-check"></i><b>10.2</b> Subsampling methods</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="subsample.html"><a href="subsample.html#uniform-subsampling-unif"><i class="fa fa-check"></i><b>10.2.1</b> Uniform subsampling (UNIF)</a></li>
<li class="chapter" data-level="10.2.2" data-path="subsample.html"><a href="subsample.html#basic-leveraging-blev"><i class="fa fa-check"></i><b>10.2.2</b> Basic leveraging (BLEV)</a></li>
<li class="chapter" data-level="10.2.3" data-path="subsample.html"><a href="subsample.html#predictor-length-sampling-pl"><i class="fa fa-check"></i><b>10.2.3</b> Predictor-length sampling (PL)</a></li>
<li class="chapter" data-level="10.2.4" data-path="subsample.html"><a href="subsample.html#comparison-of-methods"><i class="fa fa-check"></i><b>10.2.4</b> Comparison of methods</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="subsample.html"><a href="subsample.html#subsample-lin-reg"><i class="fa fa-check"></i><b>10.3</b> Linear regression model</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="subsample.html"><a href="subsample.html#a-review-of-zhu2015optimal"><i class="fa fa-check"></i><b>10.3.1</b> A review of <span class="citation"><span>Zhu et al.</span> (<span>2015</span>)</span></a></li>
<li class="chapter" data-level="10.3.2" data-path="subsample.html"><a href="subsample.html#computational-performance"><i class="fa fa-check"></i><b>10.3.2</b> Computational performance</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="subsample.html"><a href="subsample.html#classification-problems"><i class="fa fa-check"></i><b>10.4</b> Classification problems</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="subsample.html"><a href="subsample.html#optimal-subsampling-for-classification-problems"><i class="fa fa-check"></i><b>10.4.1</b> Optimal subsampling for classification problems</a></li>
<li class="chapter" data-level="10.4.2" data-path="subsample.html"><a href="subsample.html#class-syn"><i class="fa fa-check"></i><b>10.4.2</b> Synthetic data</a></li>
<li class="chapter" data-level="10.4.3" data-path="subsample.html"><a href="subsample.html#real-data-example"><i class="fa fa-check"></i><b>10.4.3</b> Real data example</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="subsample.html"><a href="subsample.html#concl"><i class="fa fa-check"></i><b>10.5</b> Conclusion</a></li>
<li class="chapter" data-level="10.6" data-path="conc.html"><a href="conc.html#appendix"><i class="fa fa-check"></i><b>10.6</b> Appendix</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="subsample.html"><a href="subsample.html#app-svd"><i class="fa fa-check"></i><b>10.6.1</b> From SVD to leverage scores</a></li>
<li class="chapter" data-level="10.6.2" data-path="subsample.html"><a href="subsample.html#app-pl"><i class="fa fa-check"></i><b>10.6.2</b> From optimal to prediction-length subsampling</a></li>
<li class="chapter" data-level="10.6.3" data-path="subsample.html"><a href="subsample.html#app-dens"><i class="fa fa-check"></i><b>10.6.3</b> Synthetic data</a></li>
<li class="chapter" data-level="10.6.4" data-path="subsample.html"><a href="subsample.html#app-sin"><i class="fa fa-check"></i><b>10.6.4</b> Subsampling applied to sinusoidal function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="outl.html"><a href="outl.html"><i class="fa fa-check"></i><b>11</b> Outliers</a>
<ul>
<li class="chapter" data-level="11.1" data-path="outl.html"><a href="outl.html#outl-trimmed"><i class="fa fa-check"></i><b>11.1</b> Trimmed mean estimator</a></li>
<li class="chapter" data-level="11.2" data-path="outl.html"><a href="outl.html#outl-mom"><i class="fa fa-check"></i><b>11.2</b> Median-of-means estimator</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">From Scratch</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="vc" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> VC theory</h1>
<p>In Chapter <a href="emp.html#emp">4</a> we defined the <em>shatter coefficient</em> as the number of times we can intersect <span class="math inline">\(\{X_1,...,X_n\}\in\mathcal{X}\)</span> with subsets <span class="math inline">\(A\)</span> of <span class="math inline">\(\mathcal{X}\)</span> that belong to the family <span class="math inline">\(\mathcal{A}\)</span>, in particular:</p>
<p><span class="math display" id="eq:shatter">\[
\begin{equation} 
\begin{aligned}
&amp;&amp; S(X_1^n,\mathcal{A})&amp;= \left|\{A\cup\{X_1,...,X_n\}:A\in\mathcal{A}\} \right| \\
\end{aligned}
\tag{5.1}
\end{equation}
\]</span></p>
<p>We further defined:</p>
<p><span class="math display" id="eq:max-shatter">\[
\begin{equation} 
\begin{aligned}
&amp;&amp; S_{\mathcal{A}}(n)&amp;=\max_{X_1,...,X_n}S(X_1^n,\mathcal{A}) \\
\end{aligned}
\tag{5.2}
\end{equation}
\]</span></p>
<p>Clearly, we have that <span class="math inline">\(S(X_1^n,\mathcal{A})\le2^n\)</span>, where <span class="math inline">\(2^n\)</span> is simply the total number of subsets of <span class="math inline">\(n\)</span> points: each point can either be in a given subset or not.</p>
<p>Suppose the class <span class="math inline">\(\mathcal{A}\)</span> shatter the <span class="math inline">\(n\)</span> points. This means that for each possible subset, we can find a set in <span class="math inline">\(\mathcal{A}\)</span> that can be intersected with the subset. In the context of our initial problem <span class="math inline">\(\mathbb{E} \max_{A\in\mathcal{A}} |P_n(A)-P(A)|\)</span> and the VC theorem, this means we are in trouble: we expect that overfitting will occur.</p>
<div id="vc-dimension" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> VC dimension</h2>
<p>Relating this back to empirical risk minimization and classification, the VC dimension corresponds to the complexity of our family <span class="math inline">\(\mathcal{C}\)</span> of classifiers. The higher the VC dimension, the higher the shatter coefficient associated with <span class="math inline">\(\mathcal{C}\)</span> for given <span class="math inline">\(n\)</span>: ultimately, high VC dimensionality can be thought of as an increased risk of overfitting.</p>
<div id="feature-maps" class="section level3" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Feature maps</h3>
<p>We often want to find an upper bound for the VC dimension of a family of classifiers. To do so in practice we just need to determine the number of feature maps <span class="math inline">\(r\)</span>.</p>
</div>
<div id="examples" class="section level3" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Examples</h3>
<p>Firstly, observe that for the set of linear half-spaces <span class="math inline">\(\mathcal{A}=\left\{ \{ X: \sum_{i=1}^{d} w_i \phi_i(X)=\mathbf{w}^T\phi(X)\ge0\}:\mathbf{w}\in \mathbb{R}^d\right\}\)</span> we in fact have <span class="math inline">\(V_{\mathcal{A}}=d\)</span>: we can simply take each element of <span class="math inline">\(X\)</span> as a feature, so <span class="math inline">\(\phi_1(X)=X_1, ..., \phi_d(X)=X_d\)</span>.</p>
</div>
</div>
<div id="stuctural-risk-minimization" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Stuctural risk minimization</h2>
<p>Let <span class="math inline">\(\mathcal{C}^{(1)}\subset\mathcal{C}^{(2)}\subset...\)</span> be a sequence of classifiers. Then for their corresponding VC dimensions we have <span class="math inline">\(V_1\le V_2\le...\)</span>. Let <span class="math inline">\(\bar{g}_k\)</span> denote the best classifier among the whole sequence - that is the classifier that minimizes <em>true</em> risk - and let <span class="math inline">\(g_n^{(k)}\)</span> denote the classifier that minimizes <em>empirical</em> risk (potentially all the way to zero). We know that the empirical risk minimizer is prone to overfitting, but we also saw in Chapter <a href="emp.html#emp">4</a> that we can bound the risk of overfitting. In particular, using the result in <a href="#cor:overfitting-vc"><strong>??</strong></a> we have that the overfitting error can be bound by</p>
<p><span class="math display">\[
\begin{aligned}
&amp;&amp; R(g_n^{(k)})-R_n(g_n^{(k)})&amp;\le c \sqrt{ \frac{V_k \log n}{n}} \\
\end{aligned}
\]</span>
where <span class="math inline">\(c\)</span> is some constant. We explicitly refrain from using absolute values here to demonstrate that we expect the difference expressed in this way to be positive. With this in mind, it seems reasonable to use this knowledge to inform our choice of <span class="math inline">\(k\)</span>, that is the complexity of our classifier. In structural risk minimization we incorporate the bound as a penalty on top of the empirical risk. This is referred as complexity regulation.</p>
<p>Complexity regularization involves choosing the value of <span class="math inline">\(k\)</span> for which <span class="math inline">\(R_n(g_n^{(k)})+c \sqrt{ \frac{V_k \log n}{n}}\)</span> is minimized. Let <span class="math inline">\(g_n\)</span> denote the classifier obtained through penalized empirical risk minimization. Then one can prove that</p>
<p><span class="math display">\[
\begin{aligned}
&amp;&amp;  \mathbb{E} R(g_n) - R^*&amp;\le \min_k \left( c \sqrt{ \frac{V_k \log n}{n}} + R(\bar{g}_k) - R^*  \right)\\
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(R^*\)</span> is the Bayes risk, <span class="math inline">\(c \sqrt{ \frac{V_k \log n}{n}}\)</span> is an upper bound for the excess risk in <span class="math inline">\(\mathcal{C}^{(k)}\)</span> - that is <span class="math inline">\(R(g_n^{(k)})-R(\bar{g}_k)\)</span> - and <span class="math inline">\(R(\bar{g}_k) - R^*\)</span> is the approximation error (bias) of the family of classifiers that we restrict ourselves to. Figure <a href="vc.html#fig:struct-min-risk">5.1</a> illustrate this approach.</p>
<div class="figure"><span id="fig:struct-min-risk"></span>
<img src="www/struct_risk_min.png" alt="(PLACEHOLDER) Structural risk minimization." width="260" />
<p class="caption">
Figure 5.1: (PLACEHOLDER) Structural risk minimization.
</p>
</div>
<p>Note that <span class="math inline">\(c \sqrt{ \frac{V_k \log n}{n}}\)</span> is not the best bound and in fact we have already seen improved versions of this, in particular the Rademacher Average in Chapter <a href="emp.html#emp">4</a>. We will cover complexity regularization in more detail in Chapter <a href="complex.html#complex">8</a>.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="emp.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="class.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": [["book.epub", "EPUB"]],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true,
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
