<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Complexity regularization | From Scratch</title>
  <meta name="description" content="A collection of ideas, notes, exercises and code." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Complexity regularization | From Scratch" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A collection of ideas, notes, exercises and code." />
  <meta name="github-repo" content="https://github.com/pat-alt/fromScratch.git" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Complexity regularization | From Scratch" />
  
  <meta name="twitter:description" content="A collection of ideas, notes, exercises and code." />
  

<meta name="author" content="Patrick Altmeyer" />


<meta name="date" content="2021-03-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="www/icon.ico" type="image/x-icon" />
<link rel="prev" href="regr.html"/>
<link rel="next" href="dim-red.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.2/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.2.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.52.2/plotly-latest.min.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.16/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/nouislider-7.0.10/jquery.nouislider.min.css" rel="stylesheet" />
<script src="libs/nouislider-7.0.10/jquery.nouislider.min.js"></script>
<link href="libs/selectize-0.12.0/selectize.bootstrap3.css" rel="stylesheet" />
<script src="libs/selectize-0.12.0/selectize.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#resources"><i class="fa fa-check"></i>Resources</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#r-package"><i class="fa fa-check"></i>R package</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#python-code"><i class="fa fa-check"></i>Python code</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#session-info"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-author.html"><a href="about-the-author.html"><i class="fa fa-check"></i>About the Author</a></li>
<li class="part"><span><b>I Part I</b></span></li>
<li class="chapter" data-level="1" data-path="introductory-topics.html"><a href="introductory-topics.html"><i class="fa fa-check"></i><b>1</b> Introductory topics</a></li>
<li class="chapter" data-level="2" data-path="conc.html"><a href="conc.html"><i class="fa fa-check"></i><b>2</b> Concentration inequalities</a>
<ul>
<li class="chapter" data-level="2.1" data-path="conc.html"><a href="conc.html#conc-mean"><i class="fa fa-check"></i><b>2.1</b> Empirical mean</a></li>
<li class="chapter" data-level="2.2" data-path="conc.html"><a href="conc.html#simple-non-asymptotic-concentration-inequalities"><i class="fa fa-check"></i><b>2.2</b> Simple non-asymptotic concentration inequalities</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="conc.html"><a href="conc.html#conc-markov"><i class="fa fa-check"></i><b>2.2.1</b> Markov’s inequality</a></li>
<li class="chapter" data-level="2.2.2" data-path="conc.html"><a href="conc.html#chebychevs-inequality"><i class="fa fa-check"></i><b>2.2.2</b> Chebychev’s inequality</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="conc.html"><a href="conc.html#asympotic-concentration-inequalities"><i class="fa fa-check"></i><b>2.3</b> Asympotic concentration inequalities</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="conc.html"><a href="conc.html#central-limit-theorem"><i class="fa fa-check"></i><b>2.3.1</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="conc.html"><a href="conc.html#exponential-non-asymptotic-concentration-inequalities"><i class="fa fa-check"></i><b>2.4</b> Exponential non-asymptotic concentration inequalities</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="conc.html"><a href="conc.html#chernoff-bounds"><i class="fa fa-check"></i><b>2.4.1</b> Chernoff bounds</a></li>
<li class="chapter" data-level="2.4.2" data-path="conc.html"><a href="conc.html#conc-hoeff"><i class="fa fa-check"></i><b>2.4.2</b> Hoeffding’s Inequality</a></li>
<li class="chapter" data-level="2.4.3" data-path="conc.html"><a href="conc.html#bernsteins-inequality"><i class="fa fa-check"></i><b>2.4.3</b> Bernstein’s inequality</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="conc.html"><a href="conc.html#conc-examples"><i class="fa fa-check"></i><b>2.5</b> Examples</a></li>
<li class="chapter" data-level="2.6" data-path="conc.html"><a href="conc.html#appendix"><i class="fa fa-check"></i><b>2.6</b> Appendix</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="conc.html"><a href="conc.html#example-of-a-moment-generating-function"><i class="fa fa-check"></i><b>2.6.1</b> Example of a moment generating function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="det-opt.html"><a href="det-opt.html"><i class="fa fa-check"></i><b>3</b> Optimization</a>
<ul>
<li class="chapter" data-level="3.1" data-path="det-opt.html"><a href="det-opt.html#line-search"><i class="fa fa-check"></i><b>3.1</b> Line search</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="det-opt.html"><a href="det-opt.html#methodology"><i class="fa fa-check"></i><b>3.1.1</b> Methodology</a></li>
<li class="chapter" data-level="3.1.2" data-path="det-opt.html"><a href="det-opt.html#results"><i class="fa fa-check"></i><b>3.1.2</b> Results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="emp.html"><a href="emp.html"><i class="fa fa-check"></i><b>4</b> Empirical risk minimization</a>
<ul>
<li class="chapter" data-level="4.1" data-path="emp.html"><a href="emp.html#emp-risks"><i class="fa fa-check"></i><b>4.1</b> Excess risk and overfitting error</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="emp.html"><a href="emp.html#data-splitting"><i class="fa fa-check"></i><b>4.1.1</b> Data splitting</a></li>
<li class="chapter" data-level="4.1.2" data-path="emp.html"><a href="emp.html#leave-one-out-cross-validation"><i class="fa fa-check"></i><b>4.1.2</b> Leave-one-out cross-validation</a></li>
<li class="chapter" data-level="4.1.3" data-path="emp.html"><a href="emp.html#realizable-case"><i class="fa fa-check"></i><b>4.1.3</b> Realizable case</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="emp.html"><a href="emp.html#rademacher-averages"><i class="fa fa-check"></i><b>4.2</b> Rademacher averages</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="emp.html"><a href="emp.html#finite-class-of-classifiers"><i class="fa fa-check"></i><b>4.2.1</b> Finite class of classifiers</a></li>
<li class="chapter" data-level="4.2.2" data-path="emp.html"><a href="emp.html#infinitely-many-classifiers"><i class="fa fa-check"></i><b>4.2.2</b> Infinitely many classifiers</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="emp.html"><a href="emp.html#towards-vc-theory"><i class="fa fa-check"></i><b>4.3</b> Towards VC theory</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="vc.html"><a href="vc.html"><i class="fa fa-check"></i><b>5</b> VC theory</a>
<ul>
<li class="chapter" data-level="5.1" data-path="vc.html"><a href="vc.html#vc-dimension"><i class="fa fa-check"></i><b>5.1</b> VC dimension</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="vc.html"><a href="vc.html#feature-maps"><i class="fa fa-check"></i><b>5.1.1</b> Feature maps</a></li>
<li class="chapter" data-level="5.1.2" data-path="vc.html"><a href="vc.html#examples"><i class="fa fa-check"></i><b>5.1.2</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="vc.html"><a href="vc.html#stuctural-risk-minimization"><i class="fa fa-check"></i><b>5.2</b> Stuctural risk minimization</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="class.html"><a href="class.html"><i class="fa fa-check"></i><b>6</b> Classification</a>
<ul>
<li class="chapter" data-level="6.1" data-path="class.html"><a href="class.html#binary-classification"><i class="fa fa-check"></i><b>6.1</b> Binary classification</a></li>
<li class="chapter" data-level="6.2" data-path="class.html"><a href="class.html#class-knn"><i class="fa fa-check"></i><b>6.2</b> Nearest Neighbour</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="class.html"><a href="class.html#nn"><i class="fa fa-check"></i><b>6.2.1</b> 1NN</a></li>
<li class="chapter" data-level="6.2.2" data-path="class.html"><a href="class.html#knn"><i class="fa fa-check"></i><b>6.2.2</b> KNN</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="class.html"><a href="class.html#linear-classification"><i class="fa fa-check"></i><b>6.3</b> Linear Classification</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="class.html"><a href="class.html#perceptron"><i class="fa fa-check"></i><b>6.3.1</b> Perceptron</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regr.html"><a href="regr.html"><i class="fa fa-check"></i><b>7</b> Regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="regr.html"><a href="regr.html#regr-ols"><i class="fa fa-check"></i><b>7.1</b> Ordinary least-squares</a></li>
<li class="chapter" data-level="7.2" data-path="regr.html"><a href="regr.html#regr-wls"><i class="fa fa-check"></i><b>7.2</b> Weighted least-squares</a></li>
<li class="chapter" data-level="7.3" data-path="regr.html"><a href="regr.html#class-logit"><i class="fa fa-check"></i><b>7.3</b> Logisitic regression</a></li>
<li class="chapter" data-level="7.4" data-path="conc.html"><a href="conc.html#appendix"><i class="fa fa-check"></i><b>7.4</b> Appendix</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="regr.html"><a href="regr.html#app-wls"><i class="fa fa-check"></i><b>7.4.1</b> Weighted least-squares</a></li>
<li class="chapter" data-level="7.4.2" data-path="regr.html"><a href="regr.html#irls"><i class="fa fa-check"></i><b>7.4.2</b> Iterative reweighted least-squares</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="complex.html"><a href="complex.html"><i class="fa fa-check"></i><b>8</b> Complexity regularization</a>
<ul>
<li class="chapter" data-level="8.1" data-path="complex.html"><a href="complex.html#reg-bias"><i class="fa fa-check"></i><b>8.1</b> Bias-variance tradeoff</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="dim-red.html"><a href="dim-red.html"><i class="fa fa-check"></i><b>9</b> Dimensionality reduction</a>
<ul>
<li class="chapter" data-level="9.1" data-path="dim-red.html"><a href="dim-red.html#random-projections"><i class="fa fa-check"></i><b>9.1</b> Random projections</a></li>
<li class="chapter" data-level="9.2" data-path="dim-red.html"><a href="dim-red.html#pca"><i class="fa fa-check"></i><b>9.2</b> PCA</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="dim-red.html"><a href="dim-red.html#the-maths-behind-pca"><i class="fa fa-check"></i><b>9.2.1</b> The maths behind PCA</a></li>
<li class="chapter" data-level="9.2.2" data-path="dim-red.html"><a href="dim-red.html#an-intuitive-example"><i class="fa fa-check"></i><b>9.2.2</b> An intuitive example</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="dim-red.html"><a href="dim-red.html#pca-for-feature-extraction"><i class="fa fa-check"></i><b>9.3</b> PCA for feature extraction</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="dim-red.html"><a href="dim-red.html#squared-elements-of-eigenvectors"><i class="fa fa-check"></i><b>9.3.1</b> Squared elements of eigenvectors</a></li>
<li class="chapter" data-level="9.3.2" data-path="dim-red.html"><a href="dim-red.html#svd"><i class="fa fa-check"></i><b>9.3.2</b> SVD</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="dim-red.html"><a href="dim-red.html#high-dimensional-data"><i class="fa fa-check"></i><b>9.4</b> High-dimensional data</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="dim-red.html"><a href="dim-red.html#regularized-svd"><i class="fa fa-check"></i><b>9.4.1</b> Regularized SVD</a></li>
<li class="chapter" data-level="9.4.2" data-path="dim-red.html"><a href="dim-red.html#fast-partial-svd"><i class="fa fa-check"></i><b>9.4.2</b> Fast, partial SVD</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="dim-red.html"><a href="dim-red.html#forward-search"><i class="fa fa-check"></i><b>9.5</b> Forward search</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="subsample.html"><a href="subsample.html"><i class="fa fa-check"></i><b>10</b> Subsampling</a>
<ul>
<li class="chapter" data-level="10.1" data-path="subsample.html"><a href="subsample.html#subsample-motivation"><i class="fa fa-check"></i><b>10.1</b> Motivation</a></li>
<li class="chapter" data-level="10.2" data-path="subsample.html"><a href="subsample.html#subsample-methods"><i class="fa fa-check"></i><b>10.2</b> Subsampling methods</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="subsample.html"><a href="subsample.html#uniform-subsampling-unif"><i class="fa fa-check"></i><b>10.2.1</b> Uniform subsampling (UNIF)</a></li>
<li class="chapter" data-level="10.2.2" data-path="subsample.html"><a href="subsample.html#basic-leveraging-blev"><i class="fa fa-check"></i><b>10.2.2</b> Basic leveraging (BLEV)</a></li>
<li class="chapter" data-level="10.2.3" data-path="subsample.html"><a href="subsample.html#predictor-length-sampling-pl"><i class="fa fa-check"></i><b>10.2.3</b> Predictor-length sampling (PL)</a></li>
<li class="chapter" data-level="10.2.4" data-path="subsample.html"><a href="subsample.html#comparison-of-methods"><i class="fa fa-check"></i><b>10.2.4</b> Comparison of methods</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="subsample.html"><a href="subsample.html#subsample-lin-reg"><i class="fa fa-check"></i><b>10.3</b> Linear regression model</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="subsample.html"><a href="subsample.html#a-review-of-zhu2015optimal"><i class="fa fa-check"></i><b>10.3.1</b> A review of <span class="citation"><span>Zhu et al.</span> (<span>2015</span>)</span></a></li>
<li class="chapter" data-level="10.3.2" data-path="subsample.html"><a href="subsample.html#computational-performance"><i class="fa fa-check"></i><b>10.3.2</b> Computational performance</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="subsample.html"><a href="subsample.html#classification-problems"><i class="fa fa-check"></i><b>10.4</b> Classification problems</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="subsample.html"><a href="subsample.html#optimal-subsampling-for-classification-problems"><i class="fa fa-check"></i><b>10.4.1</b> Optimal subsampling for classification problems</a></li>
<li class="chapter" data-level="10.4.2" data-path="subsample.html"><a href="subsample.html#class-syn"><i class="fa fa-check"></i><b>10.4.2</b> Synthetic data</a></li>
<li class="chapter" data-level="10.4.3" data-path="subsample.html"><a href="subsample.html#real-data-example"><i class="fa fa-check"></i><b>10.4.3</b> Real data example</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="subsample.html"><a href="subsample.html#concl"><i class="fa fa-check"></i><b>10.5</b> Conclusion</a></li>
<li class="chapter" data-level="10.6" data-path="conc.html"><a href="conc.html#appendix"><i class="fa fa-check"></i><b>10.6</b> Appendix</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="subsample.html"><a href="subsample.html#app-svd"><i class="fa fa-check"></i><b>10.6.1</b> From SVD to leverage scores</a></li>
<li class="chapter" data-level="10.6.2" data-path="subsample.html"><a href="subsample.html#app-pl"><i class="fa fa-check"></i><b>10.6.2</b> From optimal to prediction-length subsampling</a></li>
<li class="chapter" data-level="10.6.3" data-path="subsample.html"><a href="subsample.html#app-dens"><i class="fa fa-check"></i><b>10.6.3</b> Synthetic data</a></li>
<li class="chapter" data-level="10.6.4" data-path="subsample.html"><a href="subsample.html#app-sin"><i class="fa fa-check"></i><b>10.6.4</b> Subsampling applied to sinusoidal function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="outl.html"><a href="outl.html"><i class="fa fa-check"></i><b>11</b> Outliers</a>
<ul>
<li class="chapter" data-level="11.1" data-path="outl.html"><a href="outl.html#outl-trimmed"><i class="fa fa-check"></i><b>11.1</b> Trimmed mean estimator</a></li>
<li class="chapter" data-level="11.2" data-path="outl.html"><a href="outl.html#outl-mom"><i class="fa fa-check"></i><b>11.2</b> Median-of-means estimator</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">From Scratch</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="complex" class="section level1" number="8">
<h1><span class="header-section-number">Chapter 8</span> Complexity regularization</h1>
<div id="reg-bias" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> Bias-variance tradeoff</h2>
<p>To set the stage for the remainder of this note we will briefly revisit the bias-variance trade-off in this section. In particular we will illustrate the effect of varying the sample size <span class="math inline">\(n\)</span>. Readers familiar with this topic may choose to skip this section.</p>
<p>As as in <span class="citation"><a href="references.html#ref-bishop2006pattern" role="doc-biblioref">Bishop</a> (<a href="references.html#ref-bishop2006pattern" role="doc-biblioref">2006</a>)</span> we consider synthetic data generated by the sinusoidal function <span class="math inline">\(f(x)=\sin(2\pi x)\)</span>. To simulate random samples of <span class="math inline">\(\mathbf{y}\)</span> we sample <span class="math inline">\(n\)</span> input values from <span class="math inline">\(\mathbf{X} \sim \text{unif}(0,1)\)</span> and introduce a random noise component <span class="math inline">\(\varepsilon \sim \mathcal{N}(0,0.3)\)</span>. Figure <a href="complex.html#fig:p-sim">8.1</a> shows <span class="math inline">\(\mathbf{y}\)</span> along with random draws <span class="math inline">\(\mathbf{y}^*_n\)</span>.</p>
<div class="figure"><span id="fig:p-sim"></span>
<img src="fromScratch_files/figure-html/p-sim-1.png" alt="Sinusoidal function and random draws." width="672" />
<p class="caption">
Figure 8.1: Sinusoidal function and random draws.
</p>
</div>
<p>Following <span class="citation"><a href="references.html#ref-bishop2006pattern" role="doc-biblioref">Bishop</a> (<a href="references.html#ref-bishop2006pattern" role="doc-biblioref">2006</a>)</span> we will use a Gaussian linear model with Gaussian kernels <span class="math inline">\(\exp(-\frac{(x_k-\mu_p)^{2}}{2s^2})\)</span> as</p>
<p><span class="math display" id="eq:model">\[
\begin{equation} 
\begin{aligned}
&amp;&amp; \mathbf{y}|\mathbf{X}&amp; =f(x) \sim \mathcal{N} \left( \sum_{j=0}^{p-1} \phi_j(x)\beta_j, v \mathbb{I}_p \right) \\
\end{aligned}
\tag{8.1}
\end{equation}
\]</span></p>
<p>with <span class="math inline">\(v=0.3\)</span> to estimate <span class="math inline">\(\hat{\mathbf{y}}_k\)</span> from random draws <span class="math inline">\(\mathbf{X}_k\)</span>. We fix the number of kernels <span class="math inline">\(p=24\)</span> (and hence the number of features <span class="math inline">\(M=p+1=25\)</span>) as well as the spatial scale <span class="math inline">\(s=0.1\)</span>. To vary the complexity of the model we use a form of regularized least-squares (<em>Ridge regression</em>) and let the regularization parameter <span class="math inline">\(\lambda\)</span> vary</p>
<p><span class="math display" id="eq:reg-ls">\[
\begin{equation} 
\begin{aligned}
&amp;&amp; \hat\beta&amp;=(\lambda I + \Phi^T \Phi)^{-1}\Phi^Ty \\
\end{aligned}
\tag{8.2}
\end{equation}
\]</span></p>
<p>where high values of <span class="math inline">\(\lambda\)</span> in <a href="complex.html#eq:reg-ls">(8.2)</a> shrink parameter values towards zero. (Note that a choice <span class="math inline">\(\lambda=0\)</span> corresponds to the OLS estimator which is defined as long as <span class="math inline">\(p \le n\)</span>.)</p>
<p>As in <span class="citation"><a href="references.html#ref-bishop2006pattern" role="doc-biblioref">Bishop</a> (<a href="references.html#ref-bishop2006pattern" role="doc-biblioref">2006</a>)</span> we proceed as follows for each choice of <span class="math inline">\(\lambda\)</span> and each sample draw to illustrate the bias-variance trade-off:</p>
<ol style="list-style-type: decimal">
<li>Draw <span class="math inline">\(N=25\)</span> time from <span class="math inline">\(\mathbf{u}_k \sim \text{unif}(0,1)\)</span>.</li>
<li>Let <span class="math inline">\(\mathbf{X}_k^*=\mathbf{u}_k+\varepsilon_k\)</span> with <span class="math inline">\(\varepsilon \sim \mathcal{N}(0, 0.3)\)</span>.</li>
<li>Compute <span class="math inline">\(\mathbf{y}_k^*=\sin(2\pi \mathbf{X}^*_k)\)</span>.</li>
<li>Extract features <span class="math inline">\(\Phi_k\)</span> from <span class="math inline">\(\mathbf{X}_k^*\)</span> and estimate the parameter vector <span class="math inline">\(\beta_k^*(\Phi_k,\mathbf{y}^*_k,\lambda)\)</span> through regularized least-squares.</li>
<li>Predict <span class="math inline">\(\hat{\mathbf{y}}_k^*=\Phi \beta_k^*\)</span>.</li>
</ol>
<p>Applying the above procedure we can construct the familiar picture that demonstrates how increased model complexity increases variance while reducing bias (Figure <a href="complex.html#fig:plot-bias-var">8.2</a>). Recall that for the mean-squared error (MSE) we have</p>
<p><span class="math display" id="eq:mse">\[
\begin{equation} 
\begin{aligned}
&amp;&amp; \mathbb{E} \left( (\hat{f}_n(x)-f(x))^2 \right)
&amp;= \text{var} (\hat{f}_n(x)) + \left( \mathbb{E} \left( \hat{f}_n(x) \right) - f(x) \right)^2 \\
\end{aligned}
\tag{2.1}
\end{equation}
\]</span></p>
<p>where the first term on the right-hand side corresponds to the variance of our prediction and the second term to its (squared) bias. In Figure <a href="complex.html#fig:plot-bias-var">8.2</a> as model complexity increases the variance component of the MSE increases, while the bias term diminishes. A similar pattern would have been observed if instead of using regularization we had used OLS and let the number of Gaussian kernels (and hence the number of features <span class="math inline">\(p\)</span>) vary where higher values of <span class="math inline">\(p\)</span> correspond to increased model complexity.</p>
<div class="figure"><span id="fig:plot-bias-var"></span>
<img src="fromScratch_files/figure-html/plot-bias-var-1.png" alt="Bias-variance trade-off" width="672" />
<p class="caption">
Figure 8.2: Bias-variance trade-off
</p>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regr.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="dim-red.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": [["book.epub", "EPUB"]],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true,
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
